---
title: "Turbulence Analysis"
author: "Tingnan Hu, Peter Liu, Islina Shan, Ken Ye, Nancy Zhang"
date: "`r Sys.Date()`"
output:
  pdf_document
---

```{r setup, include = FALSE}
#global code chunk settings for knitting
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r}
# Load libraries
library(ggplot2)
library(dplyr)
library(car)
library(caret)
library(knitr)
library(kableExtra)
library(tidyverse)
library(gridExtra)
library(glmnet)
library(splines)
```

```{r}
# Load data
train <- read.csv("data-train.csv")
test <- read.csv("data-test.csv")
```

# Introduction

Turbulence is one of the fascinating topics in the research in fluid dynamics.
It is characterized by its chaotic motion, rapid fluctuations and lack of
predictable patterns. Yet, there have been numerous attempts in scientific
literature trying to model the behavior of turbulent flows, as turbulent flows
are prevalent in our world and are the underlying forces that drive plenty of
the physical processes, from wisps of smoking swirling up from the cigarette to
mixing of chemicals in industrial processes. A better understanding and
prediction of turbulent flow will help us gain a deeper insight into a wide
range of applications, such as improved aerodynamics in airplane designs and
better climatic modelling.

A subdomain in turbulent flow research deals with particle clustering in
turbulent flow focusing on small particles" behavior in turbulent fluids. For
our project, we are provided with a set of simulation results on small particle
probability distribution. The outcome variable was originally a probability
distribution for particle cluster volumes, but it was converted into its first
four raw moments, $E[X]$ to $E[X^4]$, to facilitate analysis. The predictor set
contains three variables:

-   Reynolds number, `Re`, which provides information on the type of flow a
    fluid is experiencing. A low `Re` corresponds with laminar flow (smooth and
    orderly), while a high `Re` corresponds with turbulent flow.

-   Gravitational acceleration, `Fr`, which measures the gravitational forces
    particles are experiencing.

-   Stokes number, `St`, where larger value corresponds with larger particle
    size.

The main research objective of our project will be to build a viable statistical
model to predict the response variable (first four raw moments of particle
probability distribution) using the three predictors at hand and the provided
traning set. Specifically, we are interested in the following:

-   Does there exist a significant linear relationship between the predictors
    and the raw four moments?

-   Is there any significant interaction effects between predictors on the
    response variables?

-   Does a linear regression model suffice? Do we need a more complex model to
    better explain the relationship between the predictors and responses?

-   Do the identified effects of the predictors vary for the four moments?

Ultimately, we aim for our model to capture adequate trends in our training
data, so that for a new parameter setting of (`Re`, `Fr`, `St`), we can
accurately predict its particle cluster volume distribution in terms of its four
raw moments, as well as make inference on how each parameter affects the
probability distribution for particle cluster volumes.

# Methodology

First, we examine the predictor and response variables and perform adequate
transformations. For predictor variables, we first noticed that `Fr` only takes
on 0.052, 0.3, and Inf in both our training and testing data set, and directly
using these values as they are is not viable as they contain infinity.
Therefore, we create a new categorical variable called `gravity` using the
following categorization:

```{r}
# Gravity acceleration categorization table
df <- data.frame(
  Fr = c("Fr < 0.1", "0.1 < Fr < 1", "Fr > 1"),
  Gravity = c("low gravity", "moderate gravity", "high gravity")
)

table <- kable(df) |>
    kable_styling("striped", full_width = FALSE) |>
    column_spec(1, bold = TRUE) |> 
    kable_styling(latex_options = "HOLD_position", full_width = F)

table
```

We also noticed that the predictor variable `Re` only takes on 90, 224, and 398
in both our training and testing data set. We thus create a new categorical
variable called `flow` using the following categorization:

```{r}
# Reynolds number categorization table
df2 <- data.frame(
  Re = c("Re < 100", "100 < Re < 300", "Re > 300"),
  Flow = c("low flow", "moderate flow", "high flow")
)

table2 <- kable(df2) |>
    kable_styling("striped", full_width = FALSE) |>
    column_spec(1, bold = TRUE) |> 
    kable_styling(latex_options = "HOLD_position", full_width = F)

table2
```

```{r}
# Transform variables
train <- train |>
  mutate(
    gravity = case_when(
      Fr < 0.1 ~ "low gravity",
      Fr < 1 & Fr > 0.1 ~ "moderate gravity",
      Fr > 1 ~ "high gravity"
    )
  ) |>
  mutate(
    flow = case_when(
      Re < 100 ~ "low flow",
      Re < 300 & Re > 100 ~ "moderate flow",
      Re > 300 ~ "high flow"
    )
  )
```

We then fit a simple linear regression model.

```{r}
# Fit a simple linear regression model
lm <- lm(R_moment_1 ~ St + gravity + flow, data = train)
summary(lm)
```

# Results

# Conclusion

# Appendix

## EDA

```{r}
summary(train)
```

```{r}
# Create histograms for the predictor and response variables
p.Re <- ggplot(train, aes(x = Re)) + geom_histogram()
p.Fr <- ggplot(train, aes(x = Fr)) + geom_histogram()
p.St <- ggplot(train, aes(x = St)) + geom_histogram()
p1 <- ggplot(train, aes(x = R_moment_1)) + geom_histogram()
p2 <- ggplot(train, aes(x = R_moment_2)) + geom_histogram()
p3 <- ggplot(train, aes(x = R_moment_3)) + geom_histogram()
p4 <- ggplot(train, aes(x = R_moment_4)) + geom_histogram()
```

```{r}
figure1 <- grid.arrange(p.Re, p.Fr, p.St, p1, p2, p3, p4, ncol = 3, nrow = 3)
figure1
```

```{r}
# Create scatterplots to explore relationships between predictor variables with R_moment_1
p1.Re <- ggplot(train, aes(x = Re, y = R_moment_1)) + geom_point()
p1.Fr <- ggplot(train, aes(x = Fr, y = R_moment_1)) + geom_point()
p1.St <- ggplot(train, aes(x = St, y = R_moment_1)) + geom_point()
```

```{r}
# Create scatterplots to explore relationships between predictor variables with R_moment_2
p2.Re <- ggplot(train, aes(x = Re, y = R_moment_2)) + geom_point()
p2.Fr <- ggplot(train, aes(x = Fr, y = R_moment_2)) + geom_point()
p2.St <- ggplot(train, aes(x = St, y = R_moment_2)) + geom_point()
```

```{r}
# Create scatterplots to explore relationships between predictor variables with R_moment_3
p3.Re <- ggplot(train, aes(x = Re, y = R_moment_3)) + geom_point()
p3.Fr <- ggplot(train, aes(x = Fr, y = R_moment_3)) + geom_point()
p3.St <- ggplot(train, aes(x = St, y = R_moment_3)) + geom_point()
```

```{r}
# Create scatterplots to explore relationships between predictor variables with R_moment_4
p4.Re <- ggplot(train, aes(x = Re, y = R_moment_4)) + geom_point()
p4.Fr <- ggplot(train, aes(x = Fr, y = R_moment_4)) + geom_point()
p4.St <- ggplot(train, aes(x = St, y = R_moment_4)) + geom_point()
```

```{r}
figure2 <- grid.arrange(p1.Re, p1.Fr, p1.St, p2.Re, p2.Fr, p2.St, ncol = 3, nrow = 2)
figure2
```

```{r}
figure3 <- grid.arrange(p3.Re, p3.Fr, p3.St, p4.Re, p4.Fr, p4.St, ncol = 3, nrow = 2)
figure3
```

The plot below suggests a very possible interaction effect between Stokes number
and Reynolds number on 1st Moment:

```{r}
ggplot(data = train, aes(y = R_moment_1, x = St, color = gravity, shape = flow)) + 
  geom_point() +
  labs(x = "St: Stokes Number",
       y = "1st Moment",
       title = "First moment vs. Stokes Number",
       subtitle = "faceted by Reynolds Number Level and Flow Level" )
```

## Simple Linear Regression

-   We made `Fr` a categorical variable when fitting a linear regression model,
    as `Fr` only has three unique values both in the training and testing
    dataset; one of these values is Inf, which should not be used in a linear
    regression analysis.

### First Moment

```{r}
lm.fit.m1 <- lm(R_moment_1 ~ gravity + St + flow + flow:St, data = train)
summary(lm.fit.m1)
```

Using 5-fold cross-validation to estimate the test set error

```{r}
set.seed(123) 
train.control <- trainControl(method = "cv", number = 5)
# Train the model
model <- train(R_moment_1 ~ gravity + poly(St,2) + flow + flow:St, data = train, method = "lm",
               trControl = train.control)
# Summarize the results
print(model)
```

Trying using polynomial terms up to degree of 5 for stokes number:

```{r}
get_poly <- function(response){
  fit.1 <- lm(response ~ St + gravity + flow, data=train)
  fit.2 <- lm(response ~ poly(St, 2) + gravity + flow, data=train)
  fit.3 <- lm(response ~ poly(St, 3) + gravity + flow, data=train)
  fit.4 <- lm(response ~ poly(St, 4) + gravity + flow, data=train)
  fit.5 <- lm(response ~ poly(St, 5) + gravity + flow, data=train)
  return(anova(fit.1,fit.2,fit.3,fit.4,fit.5))
}

moment1 <- get_poly(train$R_moment_1) 
print(moment1)
```

Judging from the p value for the associated F-statistics, only the first order
term is necessary.

### Moments 2-4

```{r}
lm.fit.m2 <- lm(log(R_moment_2) ~ gravity + St + flow, data = train)
summary(lm.fit.m2)

lm.fit.m3 <- lm(log(R_moment_3) ~ gravity + St + flow, data = train)
summary(lm.fit.m3)

lm.fit.m4 <- lm(log(R_moment_4) ~ gravity + St + flow, data = train)
summary(lm.fit.m4)
```

Considering a simple linear regression on the first moment: we have a 0.97
adjusted R squared value and significant F-statistics; however, the residual vs
fitted values plot indicates a obvious non-linear trend, which suggests that the
linearity assumption is violated.

## Ridge Regression

```{r}
get_ridge_MSE<- function(arg){
  
  train <- read.csv("data-train.csv")
  # test <- as.matrix(test)
  
  ridge.train.idx <- sample(1:nrow(train), nrow(train)*0.75)
  
  if(arg == 1){
    response = train$R_moment_1
    ridge.train <- subset(train[ridge.train.idx, ], select = c(St, Re, Fr, R_moment_1))
    ridge.ytest <- response[- ridge.train.idx]
    x <- model.matrix(R_moment_1~.,ridge.train)[,-1]
    y <- ridge.train$R_moment_1
  } else if(arg == 2){
    response = train$R_moment_2
    ridge.train <- subset(train[ridge.train.idx, ], select = c(St, Re, Fr, R_moment_2))
    ridge.ytest <- response[- ridge.train.idx]
    x <- model.matrix(R_moment_2~.,ridge.train)[,-1]
    y <- ridge.train$R_moment_2
  }else if(arg == 3){
    response = train$R_moment_3
    ridge.train <- subset(train[ridge.train.idx, ], select = c(St, Re, Fr, R_moment_3))
    ridge.ytest <- train$response[- ridge.train.idx]
    x <- model.matrix(R_moment_3~.,ridge.train)[,-1]
    y <- ridge.train$R_moment_3
  }else{
    response = train$R_moment_4
    ridge.train <- subset(train[ridge.train.idx, ], select = c(St, Re, Fr, R_moment_4))
    ridge.ytest <- train$response[- ridge.train.idx]
    x <- model.matrix(R_moment_4~.,ridge.train)[,-1]
    y <- ridge.train$R_moment_4
  }
  
  ridge.test <- as.matrix(subset(train[-ridge.train.idx, ], select = c(St, Re, Fr)))
  x <- subset(x, select = c(St, Re, Fr))
  
  
  grid <- 10^seq(10, -2, length = 100) # grid of values for lambda param
  cv_fit <- cv.glmnet(x, y, alpha = 0, lambda = grid)
  opt_lambda <- cv_fit$lambda.min
  
  ridge.mod <- glmnet(x, y, alpha = 0, lambda = opt_lambda)
  ridge.pred <- predict(ridge.mod, s = 4, newx = ridge.test)
  MSE <- mean((ridge.pred - ridge.ytest)^2) # calculate MSE
  return(MSE)
}

```

```{r}

MSE <- c()
col <- c("R_moment_1", "R_moment_2", "R_moment_3", "R_moment_4")

for(i in 1:4){
  val <- get_ridge_MSE(1)
  MSE <- c(MSE, val)
}

MSE_df <- data.frame(col, MSE)
```

## Natural Splines

```{r}
# moment 1
fit <- lm(R_moment_1 ~ ns(St, knots = c(1, 2)), data = train)
Stlims <- range(train$St)
St.grid <- seq(from = Stlims[1], to = Stlims[2], 0.1)
pred <- predict(fit, newdata = list(St = St.grid), se = TRUE)
plot(train$St, train$R_moment_1, col = "gray")

lines(St.grid, pred$fit, lwd = 2)
lines(St.grid, pred$fit + 2*pred$se, lty = "dashed")
lines(St.grid, pred$fit - 2*pred$se, lty = "dashed")

plot(train$St, train$R_moment_1, xlim = range(St.grid), cex = 0.5, col = "darkgrey")
title("Smoothing Spline")

fit <- smooth.spline(train$St, train$R_moment_1, df = 10)
fit2 <- smooth.spline(train$St, train$R_moment_1, cv = TRUE)
lines(fit, col = "red", lwd = 2)
lines(fit2, col = "blue", lwd = 2)
legend("topright", legend = c("10 DF", "2.00 DF"), col = c("red", "blue"),
       lty = 1, lwd = 2, cex = 0.8)
```

```{r}
# moment 2
fit <- lm(R_moment_2 ~ ns(St, knots = c(1, 2)), data = train)
Stlims <- range(train$St)
St.grid <- seq(from = Stlims[1], to = Stlims[2], 0.1)
pred <- predict(fit, newdata = list(St = St.grid), se = TRUE)
plot(train$St, train$R_moment_2, col = "gray")

lines(St.grid, pred$fit, lwd = 2)
lines(St.grid, pred$fit + 2*pred$se, lty = "dashed")
lines(St.grid, pred$fit - 2*pred$se, lty = "dashed")

plot(train$St, train$R_moment_2, xlim = range(St.grid), cex = 0.5, col = "darkgrey")
title("Smoothing Spline")

fit <- smooth.spline(train$St, train$R_moment_2, df = 10)
fit2 <- smooth.spline(train$St, train$R_moment_2, cv = TRUE)
lines(fit, col = "red", lwd = 2)
lines(fit2, col = "blue", lwd = 2)
legend("topright", legend = c("10 DF", "3.06 DF"), col = c("red", "blue"),
       lty = 1, lwd = 2, cex = 0.8)
```

```{r}
# moment 3
fit <- lm(R_moment_3 ~ ns(St, knots = c(1, 2)), data = train)
Stlims <- range(train$St)
St.grid <- seq(from = Stlims[1], to = Stlims[2], 0.1)
pred <- predict(fit, newdata = list(St = St.grid), se = TRUE)
plot(train$St, train$R_moment_3, col = "gray")

lines(St.grid, pred$fit, lwd = 2)
lines(St.grid, pred$fit + 2*pred$se, lty = "dashed")
lines(St.grid, pred$fit - 2*pred$se, lty = "dashed")

plot(train$St, train$R_moment_3, xlim = range(St.grid), cex = 0.5, col = "darkgrey")
title("Smoothing Spline")

fit <- smooth.spline(train$St, train$R_moment_3, df = 10)
fit2 <- smooth.spline(train$St, train$R_moment_3, cv = TRUE)
lines(fit, col = "red", lwd = 2)
lines(fit2, col = "blue", lwd = 2)
legend("topright", legend = c("10 DF", "3.20 DF"), col = c("red", "blue"),
       lty = 1, lwd = 2, cex = 0.8)
```

```{r}
# moment 4
fit <- lm(R_moment_4 ~ ns(St, knots = c(1, 2)), data = train)
Stlims <- range(train$St)
St.grid <- seq(from = Stlims[1], to = Stlims[2], 0.1)
pred <- predict(fit, newdata = list(St = St.grid), se = TRUE)
plot(train$St, train$R_moment_4, col = "gray")

lines(St.grid, pred$fit, lwd = 2)
lines(St.grid, pred$fit + 2*pred$se, lty = "dashed")
lines(St.grid, pred$fit - 2*pred$se, lty = "dashed")

plot(train$St, train$R_moment_4, xlim = range(St.grid), cex = 0.5, col = "darkgrey")
title("Smoothing Spline")

fit <- smooth.spline(train$St, train$R_moment_4, df = 10)
fit2 <- smooth.spline(train$St, train$R_moment_4, cv = TRUE)
lines(fit, col = "red", lwd = 2)
lines(fit2, col = "blue", lwd = 2)
legend("topright", legend = c("10 DF", "3.23 DF"), col = c("red", "blue"),
       lty = 1, lwd = 2, cex = 0.8)
```
